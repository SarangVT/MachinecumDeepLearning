{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This is a Regression Problem, where output is not classified in binary or multi-class, instead it is a regression problem, where output is a number.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dl5gretoeflgraduate.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'], inplace=True)\n",
    "#Min-Max Scaling, would be used as we know max score in GRE and TOEFL, instead of Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.iloc[:,0:-1] #All rows by : and columns from 0 to -1\n",
    "y=df.iloc[:,-1] #All rows with last column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(7, activation='relu', input_dim=7))\n",
    "model.add(Dense(7, activation='relu'))\n",
    "model.add(Dense(1, activation='linear')) #In case of linear Regression Task, the output layer must have linear as activation function\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.6430 - val_loss: 0.5947\n",
      "Epoch 2/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5148 - val_loss: 0.4697\n",
      "Epoch 3/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4082 - val_loss: 0.3782\n",
      "Epoch 4/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3343 - val_loss: 0.3124\n",
      "Epoch 5/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2800 - val_loss: 0.2546\n",
      "Epoch 6/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2264 - val_loss: 0.2029\n",
      "Epoch 7/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1797 - val_loss: 0.1562\n",
      "Epoch 8/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1372 - val_loss: 0.1162\n",
      "Epoch 9/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0935 - val_loss: 0.0839\n",
      "Epoch 10/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0692 - val_loss: 0.0592\n",
      "Epoch 11/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0484 - val_loss: 0.0422\n",
      "Epoch 12/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0348 - val_loss: 0.0317\n",
      "Epoch 13/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0292 - val_loss: 0.0258\n",
      "Epoch 14/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0209 - val_loss: 0.0231\n",
      "Epoch 15/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0185 - val_loss: 0.0217\n",
      "Epoch 16/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0169 - val_loss: 0.0210\n",
      "Epoch 17/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0184 - val_loss: 0.0205\n",
      "Epoch 18/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0169 - val_loss: 0.0201\n",
      "Epoch 19/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0185 - val_loss: 0.0196\n",
      "Epoch 20/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0172 - val_loss: 0.0192\n",
      "Epoch 21/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0183 - val_loss: 0.0188\n",
      "Epoch 22/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0159 - val_loss: 0.0185\n",
      "Epoch 23/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0153 - val_loss: 0.0181\n",
      "Epoch 24/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0148 - val_loss: 0.0177\n",
      "Epoch 25/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0161 - val_loss: 0.0173\n",
      "Epoch 26/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0172 - val_loss: 0.0169\n",
      "Epoch 27/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0169 - val_loss: 0.0166\n",
      "Epoch 28/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0157 - val_loss: 0.0162\n",
      "Epoch 29/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0141 - val_loss: 0.0158\n",
      "Epoch 30/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0140 - val_loss: 0.0155\n",
      "Epoch 31/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0141 - val_loss: 0.0152\n",
      "Epoch 32/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0119 - val_loss: 0.0148\n",
      "Epoch 33/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0127 - val_loss: 0.0145\n",
      "Epoch 34/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0124 - val_loss: 0.0142\n",
      "Epoch 35/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0124 - val_loss: 0.0139\n",
      "Epoch 36/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0141 - val_loss: 0.0136\n",
      "Epoch 37/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0118 - val_loss: 0.0133\n",
      "Epoch 38/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0114 - val_loss: 0.0130\n",
      "Epoch 39/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0105 - val_loss: 0.0127\n",
      "Epoch 40/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0119 - val_loss: 0.0124\n",
      "Epoch 41/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0109 - val_loss: 0.0121\n",
      "Epoch 42/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0114 - val_loss: 0.0119\n",
      "Epoch 43/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0109 - val_loss: 0.0116\n",
      "Epoch 44/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0095 - val_loss: 0.0113\n",
      "Epoch 45/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0099 - val_loss: 0.0111\n",
      "Epoch 46/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 47/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 48/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 49/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0088 - val_loss: 0.0101\n",
      "Epoch 50/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 51/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 52/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 53/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0084 - val_loss: 0.0093\n",
      "Epoch 54/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0077 - val_loss: 0.0091\n",
      "Epoch 55/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0083 - val_loss: 0.0089\n",
      "Epoch 56/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0079 - val_loss: 0.0087\n",
      "Epoch 57/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0073 - val_loss: 0.0086\n",
      "Epoch 58/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 59/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0075 - val_loss: 0.0082\n",
      "Epoch 60/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 61/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 62/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 63/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 64/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 65/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 66/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0057 - val_loss: 0.0072\n",
      "Epoch 67/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 68/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0068 - val_loss: 0.0070\n",
      "Epoch 69/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0055 - val_loss: 0.0069\n",
      "Epoch 70/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0065 - val_loss: 0.0067\n",
      "Epoch 71/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0065 - val_loss: 0.0067\n",
      "Epoch 72/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0063 - val_loss: 0.0065\n",
      "Epoch 73/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0059 - val_loss: 0.0065\n",
      "Epoch 74/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 75/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 76/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0057 - val_loss: 0.0062\n",
      "Epoch 77/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0057 - val_loss: 0.0062\n",
      "Epoch 78/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 79/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0054 - val_loss: 0.0060\n",
      "Epoch 80/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 81/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 82/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 83/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 84/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 85/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 86/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 87/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 88/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 89/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 90/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 91/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 92/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 93/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 94/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 95/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 96/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 97/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 98/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 99/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 100/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 101/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 102/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 103/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 104/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 105/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 106/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 107/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 108/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 109/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 110/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 111/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 112/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 113/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 114/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 115/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 116/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 117/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 118/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 119/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 120/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 121/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 122/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 123/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 124/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 125/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 126/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 127/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 128/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 129/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 130/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 131/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 132/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 133/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 134/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 135/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 136/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 137/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 138/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 139/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 140/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 141/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 142/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 143/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 144/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 145/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 146/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 147/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 148/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 149/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 150/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 151/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 152/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 153/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 154/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 155/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 156/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 157/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 158/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 159/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 160/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 161/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 162/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 163/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 164/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 165/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 166/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 167/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 168/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 169/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 170/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 171/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 172/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 173/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 174/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 175/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 176/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 177/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 178/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 179/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 180/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 181/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 182/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 183/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 184/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 185/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 186/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 187/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 188/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 189/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 190/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 191/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 192/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 193/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 194/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 195/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 196/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 197/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 198/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 199/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 200/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0036 - val_loss: 0.0041\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='Adam')\n",
    "history = model.fit(X_train_scaled, y_train, epochs=200, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7940251664127408"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cab7bb02d0>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

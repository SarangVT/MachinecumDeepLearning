{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Recurrent Neural Networks:\\nIt is a sequential model, useful for processing sequential data.\\nFor text-based data, having semantic meaning hidden in their sequence, and with varying size-input, ANNs are not useful.\\n\\nEven, if we use zero padding, then also due to large size, computation cost will increase and ultimately, even larger output can also come.\\nEven, if we adjust all problems still it will give worse results as it is disregarding the meaning in the sequence of the sentences, it doesn't have no capability of storing the sequence.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Recurrent Neural Networks:\n",
    "It is a sequential model, useful for processing sequential data.\n",
    "For text-based data, having semantic meaning hidden in their sequence, and with varying size-input, ANNs are not useful.\n",
    "\n",
    "Even, if we use zero padding, then also due to large size, computation cost will increase and ultimately, even larger output can also come.\n",
    "Even, if we adjust all problems still it will give worse results as it is disregarding the meaning in the sequence of the sentences, it doesn't have no capability of storing the sequence.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"In RNNs, the data flow timestampwise, like at t=1, 2...\n",
    "In the architecture, the output of hidden layers after activation function is served as the input at t=2 along with the second word to hidden layers, no involvement of output or input layer.\n",
    "\"\"\"\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m27\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m4\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> (124.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31\u001b[0m (124.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> (124.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31\u001b[0m (124.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, input_shape=(4,5)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Forward Propagation:\\nLet our model be previous,\\nInput: 5 nodes, First Layer: 3 nodes, Output Layer : 1 node\\nLet, say first input: Matrix(1,5) * Weight(5,3) + Bias(1,3)\\nThen, f(x), be the activation function, then f(X1W1+b1) = O1 be the output at t=1.\\nThe, the weights in retracing network Wh(3,3), O1Wh, (1,3)(3,3) = (1,3)\\nThen, at t=2, f(O1Wh+X2W2+b2 = O2, is the second output, where X2 is next input, W2 and b2 the modified weights and bias.\\nAgain, same steps O2 replaces O1.\\nIn these way in simple RNN, the timestamps of previous 10 steps.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Forward Propagation:\n",
    "Let our model be previous,\n",
    "Input: 5 nodes, First Layer: 3 nodes, Output Layer : 1 node\n",
    "Let, say first input: Matrix(1,5) * Weight(5,3) + Bias(1,3)\n",
    "Then, f(x), be the activation function, then f(X1W1+b1) = O1 be the output at t=1.\n",
    "The, the weights in retracing network Wh(3,3), O1Wh, (1,3)(3,3) = (1,3)\n",
    "Then, at t=2, f(O1Wh+X2W2+b2 = O2, is the second output, where X2 is next input, W2 and b2 the modified weights and bias.\n",
    "Again, same steps O2 replaces O1.\n",
    "In these way in simple RNN, the timestamps of previous 10 steps.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Convert text to vectors of numbers, can be done by:\\nA. Integer Encoding:\\nForm vocabulary, list of all words in our input, replace words by their indices.\\nAnd, then add zero padding to handle unequal sentences.\\n\\nIt is done internally by keras Tokenizer\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Convert text to vectors of numbers, can be done by:\n",
    "A. Integer Encoding:\n",
    "Form vocabulary, list of all words in our input, replace words by their indices.\n",
    "And, then add zero padding to handle unequal sentences.\n",
    "\n",
    "It is done internally by keras Tokenizer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "docs = [\n",
    "    'nice man',\n",
    "    'good boy',\n",
    "    'beautiful woman',\n",
    "    'pretty girl',\n",
    "    'handsome boy',\n",
    "    'idiot boy',\n",
    "    'ill-minded girl'\n",
    "    'wicked woman',\n",
    "    'mad man',\n",
    "    'notorious kid'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(oov_token='Sarang') #this token is for new words, any new word in test data would be assigned this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sarang': 1,\n",
       " 'boy': 2,\n",
       " 'man': 3,\n",
       " 'woman': 4,\n",
       " 'nice': 5,\n",
       " 'good': 6,\n",
       " 'beautiful': 7,\n",
       " 'pretty': 8,\n",
       " 'girl': 9,\n",
       " 'handsome': 10,\n",
       " 'idiot': 11,\n",
       " 'ill': 12,\n",
       " 'minded': 13,\n",
       " 'girlwicked': 14,\n",
       " 'mad': 15,\n",
       " 'notorious': 16,\n",
       " 'kid': 17}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 3],\n",
       " [6, 2],\n",
       " [7, 4],\n",
       " [8, 9],\n",
       " [10, 2],\n",
       " [11, 2],\n",
       " [12, 13, 14, 4],\n",
       " [15, 3],\n",
       " [16, 17]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(docs)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import pad_sequences\n",
    "sequences = pad_sequences(sequences, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  3,  0,  0],\n",
       "       [ 6,  2,  0,  0],\n",
       "       [ 7,  4,  0,  0],\n",
       "       [ 8,  9,  0,  0],\n",
       "       [10,  2,  0,  0],\n",
       "       [11,  2,  0,  0],\n",
       "       [12, 13, 14,  4],\n",
       "       [15,  3,  0,  0],\n",
       "       [16, 17,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

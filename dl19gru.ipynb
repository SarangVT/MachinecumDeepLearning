{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"GRU: RNN Architecture\\nht-1, ht, xt, rt, zt, ht' are all vectors flowing, except xt all must have same dimensions.\\n1. Calculate rt(reset gate)\\n2. ht'(candidate hidden state)\\n3. zt (update gate)\\n4. ht (current hidden state)\\n\\nIt comprises of 2 gates, reset and update.\\n3 ANN compared to 4 in LSTM.\\n5 point-wise operation same numbered but different in operation as compared to LSTM.\\n\\nIn reset gate,\\nht-1 © xt -> σ = rt [Reset Gate]\\n{[rt ⊗ ht-1] © xt} -> tanh =h't (candidate hidden state)\\nIn update gate,\\nht-1 © xt -> σ = zt [Update Gate]\\nNow, ht = [(1-zt) ⊗ ht-1] ⊕ [zt ⊗ h't]\\n\\nObserve, reset gate rt decides how much ht-1(previous info) flows according to xt(current input).\\nAnd, zt the update gate also decides how much ht-1 is passed and more is zt, less is ht-1(previous info).\\n\\nLSTM vs GRU:\\n1. Number of gates:\\nLSTM - 3 (Forget, Input, Output)\\nGRU - 2 (Reset, Update)\\n\\n2. Memory Units:\\nLSTM: Two separate states (Cell, hidden state)\\nGRU: Single hidden layer\\n\\n3. Parameter Count and Computational Complexity:\\nLSTM: Generally more\\nGRU: Comparatively less\\n\\n5. Empirical Performance:\\nLSTM: Slightly better than GRUs, in many tasks especially complex ones.\\nGRUs: Comparable to LSTMs, especially in simpler tasks.\\n\\n6. Choice in Practice:\\nStart with GRUs, try improving, if not possible then switch to LSTMs.\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"GRU: RNN Architecture\n",
    "ht-1, ht, xt, rt, zt, ht' are all vectors flowing, except xt all must have same dimensions.\n",
    "1. Calculate rt(reset gate)\n",
    "2. ht'(candidate hidden state)\n",
    "3. zt (update gate)\n",
    "4. ht (current hidden state)\n",
    "\n",
    "It comprises of 2 gates, reset and update.\n",
    "3 ANN compared to 4 in LSTM.\n",
    "5 point-wise operation same numbered but different in operation as compared to LSTM.\n",
    "\n",
    "In reset gate,\n",
    "ht-1 © xt -> σ = rt [Reset Gate]\n",
    "{[rt ⊗ ht-1] © xt} -> tanh =h't (candidate hidden state)\n",
    "In update gate,\n",
    "ht-1 © xt -> σ = zt [Update Gate]\n",
    "Now, ht = [(1-zt) ⊗ ht-1] ⊕ [zt ⊗ h't]\n",
    "\n",
    "Observe, reset gate rt decides how much ht-1(previous info) flows according to xt(current input).\n",
    "And, zt the update gate also decides how much ht-1 is passed and more is zt, less is ht-1(previous info).\n",
    "\n",
    "LSTM vs GRU:\n",
    "1. Number of gates:\n",
    "LSTM - 3 (Forget, Input, Output)\n",
    "GRU - 2 (Reset, Update)\n",
    "\n",
    "2. Memory Units:\n",
    "LSTM: Two separate states (Cell, hidden state)\n",
    "GRU: Single hidden layer\n",
    "\n",
    "3. Parameter Count and Computational Complexity:\n",
    "LSTM: Generally more\n",
    "GRU: Comparatively less\n",
    "\n",
    "5. Empirical Performance:\n",
    "LSTM: Slightly better than GRUs, in many tasks especially complex ones.\n",
    "GRUs: Comparable to LSTMs, especially in simpler tasks.\n",
    "\n",
    "6. Choice in Practice:\n",
    "Start with GRUs, try improving, if not possible then switch to LSTMs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Deep RNNs:\\nHere, the layers of nodes increase, but the feedback is in each node's each layer, so input is coming input+self feedback.\\nNo, additional connections are there, just RNN multiplied, is deep RNN.\\nIn notation, it is shown by horizontal and vertical nodes, with x as time axis and y as layer or depth axis.\\nNotation: Hidden unit is named as, h<sup>layer no</sup><sub>time</sub>\\nhlt = tanh([Wl][hlt-1] + [ul][hl-1t]+b)\\nPros:\\n1. Hierarchial Representation, starting layer word level, ending layer sentence or paragraph level.\\n2. Customization for Advanced Tasks\\nComplex tasks: Speech recognition, Machine Translation.\\nLarge Datasets as with small datasets Deep RNNs may cause overfitting.\\nHigh computational power available\\nNot satisfied with simpler model\\n\\nJust add multiple SimpleRNN(Number of Nodes)\\nBut, remember to set return_sequences=True in each hidden layer except last one as in last layer there is no need to pass inputs of each step.\\n\\nCons:\\n1. Overfitting\\n2. Training Time increases\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Deep RNNs:\n",
    "Here, the layers of nodes increase, but the feedback is in each node's each layer, so input is coming input+self feedback.\n",
    "No, additional connections are there, just RNN multiplied, is deep RNN.\n",
    "In notation, it is shown by horizontal and vertical nodes, with x as time axis and y as layer or depth axis.\n",
    "Notation: Hidden unit is named as, h<sup>layer no</sup><sub>time</sub>\n",
    "hlt = tanh([Wl][hlt-1] + [ul][hl-1t]+b)\n",
    "Pros:\n",
    "1. Hierarchial Representation, starting layer word level, ending layer sentence or paragraph level.\n",
    "2. Customization for Advanced Tasks\n",
    "Complex tasks: Speech recognition, Machine Translation.\n",
    "Large Datasets as with small datasets Deep RNNs may cause overfitting.\n",
    "High computational power available\n",
    "Not satisfied with simpler model\n",
    "\n",
    "Just add multiple SimpleRNN(Number of Nodes)\n",
    "But, remember to set return_sequences=True in each hidden layer except last one as in last layer there is no need to pass inputs of each step.\n",
    "\n",
    "Cons:\n",
    "1. Overfitting\n",
    "2. Training Time increases\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Variants: We can make also make, Deep GRUs, Deep LSTMs, also in them make return_sequnces=True in all layers except the last one.\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Variants: We can make also make, Deep GRUs, Deep LSTMs, also in them make return_sequnces=True in all layers except the last one.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bi-directional RNNs, LSTMs:\\nWhen output of later inputs affects outputs of first inputs, it is useful, like in ChatGPT we tell what to do with text we provided at last.\\nI love amazon, it's a great river.\\nI love amazon, for their fantastic service.\\nHere, amazon requires information in later sentence for getting its inference.\\n\\nWe would use bi-directional RNN, input would flow in both timestamps from both direction and final output would be the one concatenated with the other, otherwise RNNs are performing as it is, only their output is going as input not the other RNN.\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Bi-directional RNNs, LSTMs:\n",
    "When output of later inputs affects outputs of first inputs, it is useful, like in ChatGPT we tell what to do with text we provided at last.\n",
    "I love amazon, it's a great river.\n",
    "I love amazon, for their fantastic service.\n",
    "Here, amazon requires information in later sentence for getting its inference.\n",
    "\n",
    "We would use bi-directional RNN, input would flow in both timestamps from both direction and final output would be the one concatenated with the other, otherwise RNNs are performing as it is, only their output is going as input not the other RNN.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Bidirectional, SimpleRNN, LSTM, GRU, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m10\u001b[0m)         │           \u001b[38;5;34m500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">671</span> (2.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m671\u001b[0m (2.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">671</span> (2.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m671\u001b[0m (2.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "\tEmbedding(input_dim=50, output_dim=10, input_shape=(50, )),\n",
    "\tBidirectional(SimpleRNN(5)),\n",
    "\t#just add Bidirectional(GRU(5)) or Bidirectional(LSTM(5))\n",
    "\tDense(1, activation='sigmoid')\n",
    "])\n",
    "#Actually the parameters just double\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Applications:\\nIn NLP tasks, like chatbots.\\nSpecific, NER(Named Entity Recognition),\\nPOS Tagging (Parts of Speech),\\nMachine Translation,\\nSentiment Analysis,\\nTimeSeries Forecasting (Stock Price Prediction).\\n\\nDrawbacks:\\n1. Computational Complexity\\n2. Overfitting\\n3. Not used in applications in which all data is not available to us, like where real-time data is coming, for example in real time speech recognition, latency issues may occur.\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Applications:\n",
    "In NLP tasks, like chatbots.\n",
    "Specific, NER(Named Entity Recognition),\n",
    "POS Tagging (Parts of Speech),\n",
    "Machine Translation,\n",
    "Sentiment Analysis,\n",
    "TimeSeries Forecasting (Stock Price Prediction).\n",
    "\n",
    "Drawbacks:\n",
    "1. Computational Complexity\n",
    "2. Overfitting\n",
    "3. Not used in applications in which all data is not available to us, like where real-time data is coming, for example in real time speech recognition, latency issues may occur.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
